{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9h6X18DvEqpM1kL1lo2lm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tolani007/Fun-Data-Science-Content-from-Tiki/blob/main/Eigentiki's_first_PYSPARK_PROJECT_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I built a Content Recommendation Engine using the Alternating Least Squares (ALS) algorithm for fun, s/o N8N's dad joor."
      ],
      "metadata": {
        "id": "9w3y5q8qQGRA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MY GOAL is toBuild and evaluate a collaborative filtering model in < 60 minutes."
      ],
      "metadata": {
        "id": "vOr_0dVyQcRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will simulate 1,000 users interacting with 500 content pieces (articles/puzzles)."
      ],
      "metadata": {
        "id": "9jnj-7O5Qoir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-EYS8XrQ2zK",
        "outputId": "f7b74cce-bd8a-4d8f-b631-714310859568"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (4.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9.9 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import rand, col\n",
        "import random\n",
        "\n",
        "\n",
        "#I initialized Elite Spark Session\n",
        "spark = SparkSession.builder.appName('PersonalizedEdu').getOrCreate()\n",
        "\n",
        "#I generated synthetic Interaction Data (UserID, ContentID, EngagementScore 1-5)\n",
        "data = [(random.randint(1, 1000),  random.randint(1, 500), random.uniform(1,5)) for _ in range(10000)]\n",
        "df = spark.createDataFrame(data, ['userId', 'contentId', 'rating'])\n",
        "df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGCcWJ8eQZy4",
        "outputId": "042efa76-1110-4f91-ccee-66692317556c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+------------------+\n",
            "|userId|contentId|            rating|\n",
            "+------+---------+------------------+\n",
            "|   662|      238| 4.140210511698637|\n",
            "|   130|       71|1.0316924388696744|\n",
            "|   737|      210|1.1654720504603233|\n",
            "|   127|      307|2.3900858555450477|\n",
            "|   332|      429| 4.642856845689657|\n",
            "+------+---------+------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then I will feature enginner duh.\n",
        "ALS requires integer IDs. If your data uses UUIDs or Strings (like 'Intro_to_Quantum'), I use StringIndexer"
      ],
      "metadata": {
        "id": "OuE7OR3yTJCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "#Logic: Convert IDs  to indexed integers for the matrix\n",
        "indexer = StringIndexer(inputCol='contentId', outputCol ='contentIndex')\n",
        "df_indexed = indexer.fit(df).transform(df)\n",
        "\n",
        "#Then split my training and test set (80/20)\n",
        "(train, test) = df_indexed.randomSplit([0.8, 0.2])"
      ],
      "metadata": {
        "id": "QSvnEkjTTaJC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then I use ALS which is industry standard for scalable recommendation"
      ],
      "metadata": {
        "id": "7hCtLQ0SUT9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.recommendation import ALS\n",
        "\n",
        "#! configured a cold start \"drop\" that makes sure i do not get NAN errors when I am evaluating\n",
        "als = ALS(maxIter=10,\n",
        "          regParam=0.1,\n",
        "          userCol='userId',\n",
        "          itemCol='contentIndex',\n",
        "          ratingCol='rating',\n",
        "          coldStartStrategy='drop')\n",
        "model = als.fit(train)"
      ],
      "metadata": {
        "id": "PLFzVplpVqMK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now I evaluated YUH"
      ],
      "metadata": {
        "id": "_2URbJ9WXBtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "#Now I Evaluate\n",
        "predictions = model.transform(test)\n",
        "evaluator = RegressionEvaluator(metricName='rmse',labelCol='rating', predictionCol='prediction')\n",
        "rmse =evaluator.evaluate(predictions)\n",
        "print(f'Root-mean-square error = {rmse}')\n",
        "\n",
        "# NOw I generate my top 3 recommendations for all Users\n",
        "user_recs = model.recommendForAllUsers(3)\n",
        "user_recs.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gbjqw6T9W_26",
        "outputId": "6f01def9-2141-46d8-a731-170c245b00cb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root-mean-square error = 1.542115416041767\n",
            "+------+-----------------------------------------------------+\n",
            "|userId|recommendations                                      |\n",
            "+------+-----------------------------------------------------+\n",
            "|1     |[{448, 4.8689017}, {229, 4.773467}, {147, 4.6904407}]|\n",
            "|2     |[{25, 4.0337243}, {165, 3.9390948}, {119, 3.8045537}]|\n",
            "|3     |[{252, 3.8232355}, {140, 3.774166}, {461, 3.6913633}]|\n",
            "|4     |[{115, 4.1931653}, {128, 3.885631}, {448, 3.867343}] |\n",
            "|5     |[{14, 4.2737694}, {448, 4.1018558}, {15, 3.9511433}] |\n",
            "+------+-----------------------------------------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Eigentiki's interpretation\n",
        "\n",
        "#####So like bro imagine a massive spreadsheet. Rows are Users, colums are the puzzles. Most cells are empty because I have not done any puzzles on the Brillant app.\n",
        "\n",
        "ALS works like a detective. It breaks this big spreadsheet into smaller spreadsheets\n",
        "\n",
        "User traits and Content traits\n",
        "\n",
        "By multiplying the hiddent traits back together, the AI fills in the blanks to predict that if I liked a level 1 puzzle in a section I will probably like the level 2 of that puzzle  on the Brilliant app."
      ],
      "metadata": {
        "id": "BTYPRBavYQQE"
      }
    }
  ]
}