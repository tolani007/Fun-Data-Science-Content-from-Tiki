{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYV_dMVDxyc2",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "[![Github](https://img.shields.io/github/stars/labmlai/annotated_deep_learning_paper_implementations?style=social)](https://github.com/labmlai/annotated_deep_learning_paper_implementations)\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/labmlai/annotated_deep_learning_paper_implementations/blob/master/labml_nn/transformers/basic/autoregressive_experiment.ipynb)\n",
        "\n",
        "## Transformer Experiment\n",
        "\n",
        "This trains a simple transformer with\n",
        "[multi headed attention](https://nn.labml.ai/transformers/mha.html)\n",
        "introduced in [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
        "on an NLP auto-regression task (with Tiny Shakespeare dataset)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AahG_i2y5tY9",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Install the packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCzmCrAIVg0L",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "!pip install labml labml-nn --upgrade --quiet"
      ],
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE2VUQ6L5zxI",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hJXx_g0wS2C",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "from labml import experiment\n",
        "from labml_nn.transformers.basic.autoregressive_experiment import Configs\n",
        "from labml import experiment\n",
        "from labml_nn.transformers.basic.autoregressive_experiment import Configs"
      ],
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lpggo0wM6qb-",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Create an experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFcr9k-l4cAg",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "experiment.create(name=\"transformer\", writers={'screen'})\n"
      ],
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OnHLi626tJt",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Piz0c5f44hRo",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "\n",
        "conf = Configs()"
      ],
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwMzCqpD6vkL",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Set experiment configurations and assign a configurations dictionary to override configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDlt7dp-5ALt",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [],
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 29
        },
        "id": "e6hmQhTw4nks",
        "outputId": "8dfc8d86-4d48-4345-e04f-fd2c40fa26af",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "experiment.configs(conf, {#character level tokenizer\n",
        "                          'tokenizer':'character',\n",
        "                          #prompt separator is blank\n",
        "                          'prompt_separator':'',\n",
        "                          #starting prompt for smapling\n",
        "                          'prompt':'It is ',\n",
        "                          # tiny desk dataset\n",
        "                          'text':'tiny_shakespeare',\n",
        "                          #context size of %256%\n",
        "                          'seq_len':512,\n",
        "                          #train for 32 epochs\n",
        "                          'epochs': 32,\n",
        "                          #batch size 32%\n",
        "                          'batch_size':16,\n",
        "                          #swithc between training and validation 10 times\n",
        "                          'inner_iterations':10,\n",
        "\n",
        "                          #model size\n",
        "                          'd_model': 256,\n",
        "                          'transformer.n_heads': 16,\n",
        "                          'transformer.ffn.d_ff': 1024,\n",
        "                          'optimizer.optimizer': 'Noam',\n",
        "                          'optimizer.learning_rate': 1\n",
        "                          })\n",
        "\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"overflow-x: scroll;\"></pre>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvI7MtgJ61w5",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Set PyTorch models for loading and saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJZRf8527GxL",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Start the experiment and run the training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "aIAWo7Fw5DR8",
        "outputId": "562ac41c-b659-4c51-8726-6a99bebf28c2",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "import os\n",
        "import labml.tracker # Import tracker to patch it if needed\n",
        "from labml.internal.configs.base import Configs as BaseConfigs # Import base Configs class for patching\n",
        "\n",
        "# Define the path to the problematic .pid file from the error message\n",
        "pid_file_path = \"/content/logs/transformers/8d0f1744c8f711f08a7a0242ac1c000c/run.pid\"\n",
        "\n",
        "# Check if the file exists and delete it\n",
        "if os.path.exists(pid_file_path):\n",
        "    os.remove(pid_file_path)\n",
        "    print(f\"Removed stale PID file: {pid_file_path}\")\n",
        "\n",
        "# Patch labml.tracker.set_text if it doesn't exist\n",
        "if not hasattr(labml.tracker, 'set_text'):\n",
        "    print(\"Patching labml.tracker.set_text as it does not exist.\")\n",
        "    labml.tracker.set_text = lambda *args, **kwargs: None\n",
        "\n",
        "# Patch labml.tracker.debug if it doesn't exist\n",
        "if not hasattr(labml.tracker, 'debug'):\n",
        "    print(\"Patching labml.tracker.debug as it does not exist.\")\n",
        "    labml.tracker.debug = lambda *args, **kwargs: None\n",
        "\n",
        "# Store the original __setattr__ method of the base Configs class\n",
        "_original_base_configs_setattr = BaseConfigs.__setattr__\n",
        "\n",
        "# Define a custom __setattr__ to bypass the 'Cannot set after it was accessed' error for 'state_modules'\n",
        "def _patched_base_configs_setattr(self, key, value):\n",
        "    if key == 'state_modules' and hasattr(self, '__cached'):\n",
        "        # If 'state_modules' is being set, bypass the cache check.\n",
        "        # Directly set the value in __values and ensure it's not in __cached.\n",
        "        # This assumes 'state_modules' is a configuration item, stored in __values.\n",
        "        self.__values[key] = value\n",
        "        if key in self.__cached:\n",
        "            del self.__cached[key] # Ensure it's not cached after setting\n",
        "    else:\n",
        "        # For all other attributes, or if 'state_modules' logic doesn't apply, use the original method\n",
        "        _original_base_configs_setattr(self, key, value)\n",
        "\n",
        "# Apply the patch to the BaseConfigs class\n",
        "BaseConfigs.__setattr__ = _patched_base_configs_setattr\n",
        "\n",
        "try:\n",
        "    # Start the experiment\n",
        "    with experiment.start():\n",
        "         conf.run()\n",
        "finally:\n",
        "    # Ensure the original __setattr__ is restored after the experiment runs or fails\n",
        "    BaseConfigs.__setattr__ = _original_base_configs_setattr\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed stale PID file: /content/logs/transformers/8d0f1744c8f711f08a7a0242ac1c000c/run.pid\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"overflow-x: scroll;\">\n",
              "<strong><span style=\"text-decoration: underline\">transformers</span></strong>: <span style=\"color: #208FFB\">8d0f1744c8f711f08a7a0242ac1c000c</span>\n",
              "[clean]: <strong><span style=\"color: #DDB62B\">\"\"</span></strong>\n",
              "<strong><span style=\"color: #DDB62B\">       0:  </span></strong>Sample:<span style=\"color: #C5C1B4\">  ...</span><span style=\"color: #208FFB\">  0ms  </span>  <span style=\"color: #208FFB\">0ms</span><span style=\"color: #D160C4\">  0:04m/  0:00m  </span></pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot set Configs:state_modules after it was accessed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3136183448.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Start the experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m          \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# Ensure the original __setattr__ is restored after the experiment runs or fails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/labml_nn/helpers/trainer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmonit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initialize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/labml_nn/experiments/nlp_autoregression.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# states between training and validation for RNNs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# This will keep the accuracy metric stats separate for training and validation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_modules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mother_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3136183448.py\u001b[0m in \u001b[0;36m_patched_base_configs_setattr\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# For all other attributes or if 'state_modules' is not in the cache, use the original method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0m_original_base_configs_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Apply the patch to the BaseConfigs class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/labml/internal/configs/base.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cached\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cannot set {self.__class__.__name__}:{key} after it was accessed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot set Configs:state_modules after it was accessed"
          ]
        }
      ],
      "execution_count": 22
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBXXlP2b7XZO",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Transformer",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}