{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The commented code cells are Akinbobola Tolani Akinola retyping the whole process to gain MLOps intuition,  automaticity, expertise and first principles training\n"
      ],
      "metadata": {
        "id": "0E9s7PG7LZr3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlP6XkBAuSV9"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Third Edition](https://www.manning.com/books/deep-learning-with-python-third-edition). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "The book's contents are available online at [deeplearningwithpython.io](https://deeplearningwithpython.io)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmzUM7qfuSWG",
        "outputId": "70693b03-9f54-471d-fb8c-33f075db9fc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "keras-nlp 0.21.1 requires keras-hub==0.21.1, but you have keras-hub 0.25.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install keras keras-hub --upgrade -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99I1DPbouSWM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "#os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n"
      ],
      "metadata": {
        "id": "kWBkG0rZIdcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PrUnCrcvIdIj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-YXRdTjuSWN"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import os\n",
        "from IPython.core.magic import register_cell_magic\n",
        "\n",
        "@register_cell_magic\n",
        "def backend(line, cell):\n",
        "    current, required = os.environ.get(\"KERAS_BACKEND\", \"\"), line.split()[-1]\n",
        "    if current == required:\n",
        "        get_ipython().run_cell(cell)\n",
        "    else:\n",
        "        print(\n",
        "            f\"This cell requires the {required} backend. To run it, change KERAS_BACKEND to \"\n",
        "            f\"\\\"{required}\\\" at the top of the notebook, restart the runtime, and rerun the notebook.\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfQ_Q6kruSWO"
      },
      "source": [
        "## The mathematical building blocks of neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UlZ2UeiuSWR"
      },
      "source": [
        "### A first look at a neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NW5gxJfEuSWS"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.datasets import mnist\n",
        "#(train_images, train_labels),  (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "Mq3Tz3_2Lz7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MyGwZBfuSWU"
      },
      "outputs": [],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# i will looka at my training data\n",
        "#train_images.shape"
      ],
      "metadata": {
        "id": "hSKayM-pMZtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbKnRZ1tuSWV"
      },
      "outputs": [],
      "source": [
        "len(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#len(train_labels)"
      ],
      "metadata": {
        "id": "yx2X4mGKMlsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ApktbjGuSWV"
      },
      "outputs": [],
      "source": [
        "train_labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_labels"
      ],
      "metadata": {
        "id": "lC27VO5IMvDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9-3F0O0uSWW"
      },
      "outputs": [],
      "source": [
        "test_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_images"
      ],
      "metadata": {
        "id": "O15bTgROMzEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eYWxdZnuSWW"
      },
      "outputs": [],
      "source": [
        "len(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#len(test_labels)"
      ],
      "metadata": {
        "id": "bRIb4e3zM1zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5A9J_qIuSWX"
      },
      "outputs": [],
      "source": [
        "test_labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_labels"
      ],
      "metadata": {
        "id": "3pjhJuwSM9Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The workflow is that I will feed my neural network the training data, train_images and train_labels. The network will then learn to associate images and label.\n",
        "Then I will ask my network to make predictions for test_images and I will verify if my predictions match the labels from test_labels"
      ],
      "metadata": {
        "id": "2pbTF7FiNHA7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h12Xcj-JuSWX"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import keras\n",
        "#from keras import layers\n",
        "#model = keras.Sequential(\n",
        "#   [\n",
        "#       layers.Dense(512, activation=\"relu\"),\n",
        "#       layers.Dense(10, activation=\"softmax\"),\n",
        " #   ]\n",
        "#)"
      ],
      "metadata": {
        "id": "RDvdEGy3NqVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tiki: mental map\n",
        "\n",
        "core building block = layer\n",
        "\n",
        "layer = filter for data\n",
        "\n",
        "in goes data theough layer out goes useful form (data repping)\n",
        "\n",
        "I am chaining layers for progressive data distillation\n",
        "\n",
        "my deep learning models are like a sieve for data processing\n",
        "\n",
        "my deep learning models are made of a succession of higher refined data filters\n",
        "\n",
        "my deep learning models are made of a succession of increasingly refined layers\n",
        "\n",
        "here my model contains 2 dense layers that are fully connected.\n",
        "\n",
        "My 2nd/last layer is a 10-way softmax classification layer that returns an array of 10 probability scores all summing to 1.\n",
        "\n",
        "Each score is the probability that the current digit image belongs to one of my 10 digit classes.\n",
        "\n",
        "When i want to ready my model for traing I pick 3 more things as part of my copilation step\n",
        "\n",
        "the three things are my **loss function, my optimizer and my metrics to monitor** during training and testing\n",
        "\n"
      ],
      "metadata": {
        "id": "2C26xhvJOi1W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgFmoKV9uSWX"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.compile(\n",
        "#    optimizer=\"adam\",\n",
        "#    loss=\"sparse_categorical_crossentropy\",\n",
        "#    metrics=[\"accuracy\"],\n",
        "#)"
      ],
      "metadata": {
        "id": "YNE3INTKRsIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before training I preprocess my data by reshaping it into a shape that my model expectects and scaling it so tha tall values are in the [0,1] interval"
      ],
      "metadata": {
        "id": "LZ4GaQQKSnO0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7KyyPAauSWY"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_images = train_images.reshape((60000, 28*28))\n",
        "#train_images = train_images.astype(\"float32\")/ 255\n",
        "\n",
        "#test_images = test_images.reshape((60000, 28*28))\n",
        "#test_images = test_images.astype(\"float32\") / 255\n"
      ],
      "metadata": {
        "id": "LxEWzO0HTCV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I will train my model by fiting my model to the data in Keras"
      ],
      "metadata": {
        "id": "kGtnnzUpT95Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-lWmEV6uSWY"
      },
      "outputs": [],
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "metadata": {
        "id": "AMk3hnoVUKSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now that I have trained my model I can use it to predict class probabilities for new digits\n",
        "\n",
        "i can predict tje class probabilities for images that were not in my training data, like the ones in my test set"
      ],
      "metadata": {
        "id": "79bBcrDDUmhJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "vBYf6Wq9uSWZ",
        "outputId": "3187852b-3e0d-4caa-c504-08492a72285a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test_images' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1593839468.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_digits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_digits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_images' is not defined"
          ]
        }
      ],
      "source": [
        "test_digits = test_images[0:10]\n",
        "predictions = model.predict(test_digits)\n",
        "predictions[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_digits = test_images[0:10]\n",
        "#predictions = model.predict(test_digits)\n",
        "#predictions[0]"
      ],
      "metadata": {
        "id": "LQAs1zEYVjE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "each number of index i i nthe predictions array corresponds to the probability that digit image test_digits[0] bleongs to class i\n",
        "the first test digit has the highest probability at index7 so according to my model it must be a 7."
      ],
      "metadata": {
        "id": "G4s94h0gWaYT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y26GS_qHuSWZ"
      },
      "outputs": [],
      "source": [
        "predictions[0].argmax()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions[0].argmax()"
      ],
      "metadata": {
        "id": "3WVKj5xvW9--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHhki4p-uSWZ"
      },
      "outputs": [],
      "source": [
        "predictions[0][7]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions[0][7]"
      ],
      "metadata": {
        "id": "RufDAeBUXLb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4nFJIgfuSWZ"
      },
      "outputs": [],
      "source": [
        "test_labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_labels[0]"
      ],
      "metadata": {
        "id": "UY9fXrr_XSrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "if i want to know how good my model is at classifyinh new digit images i compute the accuracy over my whole test set"
      ],
      "metadata": {
        "id": "FsO9DNaxXegY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynfd9f4iuSWZ"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"test_acc: {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "#print(f'test_acc: {test_acc}')"
      ],
      "metadata": {
        "id": "DHnriHGwYeSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH_geWkVuSWa"
      },
      "source": [
        "### Data representations for neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOY5zlWyuSWb"
      },
      "source": [
        "#### Scalars (rank-0 tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zs5qw7juuSWb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x = np.array(12)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "#x = np.array(12)\n",
        "#x"
      ],
      "metadata": {
        "id": "6UNJNDF59q66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XidK_0SGuSWc"
      },
      "outputs": [],
      "source": [
        "x.ndim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#x.ndim gives me the number axes in my tensor/array"
      ],
      "metadata": {
        "id": "323dmzXh93k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tiki mind map\n",
        "\n",
        "an array of numbers = vector\n",
        "\n",
        "vector = rank - 1 tensor\n",
        "\n",
        "rank - 1 tensor = 1 axis\n"
      ],
      "metadata": {
        "id": "ObYNh9nZ-Y9j"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXvRmWiZuSWc"
      },
      "source": [
        "#### Vectors (rank-1 tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTSLh9J0uSWc"
      },
      "outputs": [],
      "source": [
        "x = np.array([12, 3, 6, 14, 7])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#numpy vector by tiki:\n",
        "#x = np.array([12,3,6,14,7])\n",
        "#x"
      ],
      "metadata": {
        "id": "h1VJ3qme-xnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bCkoXF6uSWc"
      },
      "outputs": [],
      "source": [
        "x.ndim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#x.ndim gives me the number of axes i nmy tensor slash vector"
      ],
      "metadata": {
        "id": "PoVm6F44_AVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKNcaI0suSWd"
      },
      "source": [
        "#### Matrices (rank-2 tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvenMxY9uSWe"
      },
      "outputs": [],
      "source": [
        "x = np.array([[5, 78, 2, 34, 0],\n",
        "              [6, 79, 3, 35, 1],\n",
        "              [7, 80, 4, 36, 2]])\n",
        "x.ndim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#x = np.array([[5, 78, 2, 34, 0],\n",
        "#              [6, 79, 3, 35, 1],\n",
        "#              [7, 80, 4, 36, 2]])\n",
        "#x.ndim"
      ],
      "metadata": {
        "id": "DJH_VZYbAeh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#I can put my matrices rank 2 tensors in a anew array to make a rank 3 tensor"
      ],
      "metadata": {
        "id": "IVrbBqTdBOwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K835a9IuSWf"
      },
      "source": [
        "#### Rank-3 tensors and higher-rank tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tupVwQcouSWf"
      },
      "outputs": [],
      "source": [
        "x = np.array([[[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]]])\n",
        "x.ndim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#x = np.array([[[5, 78, 2, 34, 0],\n",
        "#               [6, 79, 3, 35, 1],\n",
        "#               [7, 80, 4, 36, 2]],\n",
        "#              [[5, 78, 2, 34, 0],\n",
        "#               [6, 79, 3, 35, 1],\n",
        "#               [7, 80, 4, 36, 2]],\n",
        "#              [[5, 78, 2, 34, 0],\n",
        "#               [6, 79, 3, 35, 1],\n",
        "#               [7, 80, 4, 36, 2]]])\n",
        "#x.ndim"
      ],
      "metadata": {
        "id": "oFSV-cSrBa12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHfbVI3guSWg"
      },
      "source": [
        "#### Key attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0c-MfIAuSWg"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.datasets import mnist\n",
        "#(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "36fYvUlWWsRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q16e3tDYuSWh"
      },
      "outputs": [],
      "source": [
        "train_images.ndim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_images.ndim"
      ],
      "metadata": {
        "id": "9UKjVea8XJGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3W1OVIOuSWh"
      },
      "outputs": [],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_images.shape"
      ],
      "metadata": {
        "id": "X0_71N-iXOFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVZhnhiVuSWh"
      },
      "outputs": [],
      "source": [
        "train_images.dtype"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_images.dtype"
      ],
      "metadata": {
        "id": "_G9f61QaXSK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tABckpOUuSWh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "digit = train_images[4]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iWant toplt an image from my dataset the fourth one exactly\n",
        "#import matplotlib.pyplot asplt\n",
        "#digit = train_images[4]\n",
        "#plt.imshow(digit, cmap=plt.cm.binary)\n",
        "#plt.show"
      ],
      "metadata": {
        "id": "sEh-He0bXYZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Sr6aHC7uSWp"
      },
      "outputs": [],
      "source": [
        "train_labels[4]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the label value given to the 4th image in my traing images dataset\n",
        "#train_labels[4]"
      ],
      "metadata": {
        "id": "T8cvX79sYDCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We7Klv0muSWp"
      },
      "source": [
        "#### Manipulating tensors in NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xkgjpFYuSWq"
      },
      "outputs": [],
      "source": [
        "my_slice = train_images[10:100]\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#my_slice = train_images[10:100]\n",
        "#my_slice.shape"
      ],
      "metadata": {
        "id": "TOEA7-e2YUGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ubzghw0uSWq"
      },
      "outputs": [],
      "source": [
        "my_slice = train_images[10:100, :, :]\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#my_slice = train_images[10:100,  :, :]\n",
        "#my_slice.shape"
      ],
      "metadata": {
        "id": "mfRQtMDWYhgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4DbDLosuSWq"
      },
      "outputs": [],
      "source": [
        "my_slice = train_images[10:100, 0:28, 0:28]\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#my_slice = train_images[10:100, 0:28, 0:28]\n",
        "#my_slice.shape"
      ],
      "metadata": {
        "id": "l2zBPYM_Yyr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyobIHO1uSWq"
      },
      "outputs": [],
      "source": [
        "my_slice = train_images[:, 14:, 14:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#my_slice = train_images[:, 14:, 14:]"
      ],
      "metadata": {
        "id": "hB5vTYG6ZJ6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ORp23ICuSWq"
      },
      "outputs": [],
      "source": [
        "my_slice = train_images[:, 7:-7, 7:-7]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#my_slice = train_images[:, 7:-7, 7:-7]"
      ],
      "metadata": {
        "id": "8QPbCegXZV72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YtQwP_ZuSWt"
      },
      "source": [
        "#### The notion of data batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P33c3NEAuSWw"
      },
      "outputs": [],
      "source": [
        "batch = train_images[:128]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#batch = train_images[:128]"
      ],
      "metadata": {
        "id": "ByxH5rZPaTHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZJvtWFquSWw"
      },
      "outputs": [],
      "source": [
        "batch = train_images[128:256]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#batch = train_images[128:256]"
      ],
      "metadata": {
        "id": "B5k6PwqbaaBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kzyz5HZuSWy"
      },
      "outputs": [],
      "source": [
        "n = 3\n",
        "batch = train_images[128 * n : 128 * (n + 1)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#n = 3\n",
        "#batch = train_images[128 * n : 128 * (n + 1)]"
      ],
      "metadata": {
        "id": "H1a-zEY7agxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhndB5fjuSWz"
      },
      "source": [
        "#### Real-world examples of data tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4D4wwe5uSWz"
      },
      "source": [
        "##### Vector data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iisrLF9kuSWz"
      },
      "source": [
        "##### Timeseries data or sequence data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ280ZViuSW0"
      },
      "source": [
        "##### Image data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6aWyT13uSW0"
      },
      "source": [
        "##### Video data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFm4bSTFuSW0"
      },
      "source": [
        "### The gears of neural networks: Tensor operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrov9WnUuSW0"
      },
      "source": [
        "#### Element-wise operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMC_IbsiuSW1"
      },
      "outputs": [],
      "source": [
        "def naive_relu(x):\n",
        "    assert len(x.shape) == 2\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] = max(x[i, j], 0)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#def naive_relu(x):\n",
        "#  assert len(x.shape) == 2\n",
        "#  x = x.copy()\n",
        "#  for i in range(x.shape[0]):\n",
        "#    for j in range(x.sahpe[1]):\n",
        "#      x[i,j] = max(x[i,j],0)\n",
        "\n",
        "#    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "OwVdKntDLWqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4haZLqaUuSW1"
      },
      "outputs": [],
      "source": [
        "def naive_add(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert x.shape == y.shape\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] += y[i, j]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#def naive_add(x,y):\n",
        "#  assert len(x.shape) == 2\n",
        "#  assert x.shape == y.shape\n",
        "#  x = x.copy()\n",
        "#  for i in range(x.shape[0]):\n",
        "#    for j in ramge(len(x.shape[1])):\n",
        "#      x[i,j]+= y[i,j]\n",
        "#  return x"
      ],
      "metadata": {
        "id": "df59rI27Rwhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ3A8rRPuSW1"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "x = np.random.random((20, 100))\n",
        "y = np.random.random((20, 100))\n",
        "\n",
        "t0 = time.time()\n",
        "for _ in range(1000):\n",
        "    z = x + y\n",
        "    z = np.maximum(z, 0.0)\n",
        "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import time\n",
        "#x = np.random.random((20,100))\n",
        "#y = np.random.random((20,100))\n",
        "\n",
        "#t0 = time.time()\n",
        "#for _ in range(1000):\n",
        "#  z = x + y\n",
        "#  z = np.maximum(z, 0.0)\n",
        "#  print(\"Took: {0: .2f} s\".format(time.time() - t0))"
      ],
      "metadata": {
        "id": "-XRLJ-cDOIrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJqd8QuxuSW1"
      },
      "outputs": [],
      "source": [
        "t0 = time.time()\n",
        "for _ in range(1000):\n",
        "    z = naive_add(x, y)\n",
        "    z = naive_relu(z)\n",
        "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#t0= time.time()\n",
        "#for _ in range(1000):\n",
        "#z = naive_add(x, y)\n",
        "#z = naive_relu(z)\n",
        "#print('Took: {0:.2f} s'.format(time.time() - t0))"
      ],
      "metadata": {
        "id": "2amrhoAdU2oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBoVn8OouSW2"
      },
      "source": [
        "#### Broadcasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdas9cuJuSW2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.random.random((32, 10))\n",
        "y = np.random.random((10,))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "#X = np.random.ramdom((32,10))\n",
        "#y = np.random.random((10,))"
      ],
      "metadata": {
        "id": "psbPrIVSyCE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vre6b2pYuSW2"
      },
      "outputs": [],
      "source": [
        "y = np.expand_dims(y, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y = np.expand_dims(y, axis=0)"
      ],
      "metadata": {
        "id": "esFzzUY9yRvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA8yHuPVuSW3"
      },
      "outputs": [],
      "source": [
        "Y = np.tile(y, (32, 1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Y = np.tile(y, (32, 1))"
      ],
      "metadata": {
        "id": "fCMBYk13ye_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0DTidOjuSW3"
      },
      "outputs": [],
      "source": [
        "def naive_add_matrix_and_vector(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert len(y.shape) == 1\n",
        "    assert x.shape[1] == y.shape[0]\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] += y[j]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#def naive_add_matrix_and_vector(x, y):\n",
        "#  assert len(x.shape) == 2\n",
        "#  assert len(y.shape) == 1\n",
        "#  assert x.shape[1] == y.shape[0]\n",
        "#  x = x.copy()\n",
        "#  for i in range(x.shape[0]):\n",
        "#    for j in range(x.shape[1]):\n",
        "#      x[i,j] += y[j]\n",
        "#  return x"
      ],
      "metadata": {
        "id": "rFrwPzMKyyDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2FFc2mfuSW4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.random.random((64, 3, 32, 10))\n",
        "y = np.random.random((32, 10))\n",
        "z = np.maximum(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "#x = np.random.random((64, 3, 32, 10))\n",
        "#y = np.random.random((32, 10))\n",
        "#z = np.maximum(x, y)"
      ],
      "metadata": {
        "id": "skcMi2ZUz8dM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yes_sjuduSW4"
      },
      "source": [
        "#### Tensor product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEDUSzVsuSW4"
      },
      "outputs": [],
      "source": [
        "x = np.random.random((32,))\n",
        "y = np.random.random((32,))\n",
        "\n",
        "z = np.matmul(x, y)\n",
        "z = x @ y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#x = np.random.random((32,))\n",
        "#y = np.random.random((32,))\n",
        "\n",
        "#z = np.matmul(x,y)\n",
        "#z= x @ y"
      ],
      "metadata": {
        "id": "5yJDVT8t0azg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlKtCw20uSW4"
      },
      "outputs": [],
      "source": [
        "def naive_vector_product(x, y):\n",
        "    assert len(x.shape) == 1\n",
        "    assert len(y.shape) == 1\n",
        "    assert x.shape[0] == y.shape[0]\n",
        "    z = 0.0\n",
        "    for i in range(x.shape[0]):\n",
        "        z += x[i] * y[i]\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#def naive_vector_product(x,y):\n",
        "#  assert len(x.shape) == 1\n",
        "#  assert len(y.shape) == 1\n",
        "#  assert x.shape[0] == y.shape[0]\n",
        "#  z = 0.0\n",
        "#  for i in range(x.shape[0]):\n",
        "#    z += x[i] * y[i]\n",
        "#  return z"
      ],
      "metadata": {
        "id": "bt8eBVfE01hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUVfVVNtuSW5"
      },
      "outputs": [],
      "source": [
        "def naive_matrix_vector_product(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert len(y.shape) == 1\n",
        "    assert x.shape[1] == y.shape[0]\n",
        "    z = np.zeros(x.shape[0])\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            z[i] += x[i, j] * y[j]\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_matrix_vector_product(x,y):\n",
        "  assert len(x.shape) == 2\n",
        "  assert len(y.shape) == 1\n",
        "  assert x.shape[1] == y.shape[0]\n",
        "  z = np.zeroz(x.shape[0])\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(x.shape[1]):\n",
        "      z[i] += x[i, j] * y[j]\n",
        "  return z"
      ],
      "metadata": {
        "id": "efiKSlWv1o6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFKoH-YPuSW5"
      },
      "outputs": [],
      "source": [
        "def naive_matrix_vector_product(x, y):\n",
        "    z = np.zeros(x.shape[0])\n",
        "    for i in range(x.shape[0]):\n",
        "        z[i] = naive_vector_product(x[i, :], y)\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#def naive_matrix_vector_product(x, y):\n",
        "#  z = np.zeros(x.shape[0])\n",
        "#  for i in range(x.shape[0]):\n",
        "#    z[i] = naive_vector_product(x[i, :], y)\n",
        "#    return z"
      ],
      "metadata": {
        "id": "DZaDm33o2lkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nisYq9jouSW5"
      },
      "outputs": [],
      "source": [
        "def naive_matrix_product(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert len(y.shape) == 2\n",
        "    assert x.shape[1] == y.shape[0]\n",
        "    z = np.zeros((x.shape[0], y.shape[1]))\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(y.shape[1]):\n",
        "            row_x = x[i, :]\n",
        "            column_y = y[:, j]\n",
        "            z[i, j] = naive_vector_product(row_x, column_y)\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#def naive_matrix_product(x,y):\n",
        "#  assert len(x.shape) == 2\n",
        "#  assert len(y.shape) == 2\n",
        "#  assert x.shape[1] == y.shape[0]\n",
        "#  z = np.zeros((x.shape[0], y.shape[1]))\n",
        "#  for i in range(x.shape[0]):\n",
        "#    for j in range(y.shape[1]):\n",
        "#      row_x = x[i, :]\n",
        "#      column_y = y[:,j]\n",
        "#      z[i,j] = naive_vector_product(row_x, column_y)\n",
        "#  return z"
      ],
      "metadata": {
        "id": "6OF_5lKO3TYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9W7BwuNuSW7"
      },
      "source": [
        "#### Tensor reshaping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOryle-juSW7"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_images = train_images.reshape((60000, 28 * 28))"
      ],
      "metadata": {
        "id": "oFW3r8OyYEdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoaRUKb8uSW7"
      },
      "outputs": [],
      "source": [
        "x = np.array([[0., 1.],\n",
        "              [2., 3.],\n",
        "              [4., 5.]])\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#x = np.array([[0, 1],\n",
        "#              [2, 3],\n",
        "#              [4, 5]])\n",
        "#x.shape"
      ],
      "metadata": {
        "id": "j0Rw2oHeYPIw",
        "outputId": "45de85eb-7743-402e-ea3c-445e439a1bb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_D5A2dCuSW8"
      },
      "outputs": [],
      "source": [
        "x = x.reshape((6, 1))\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.reshape((6, 1))\n",
        "x"
      ],
      "metadata": {
        "id": "SBvHKA2YcarW",
        "outputId": "3a3e410e-5207-4126-d654-3e37c43544ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [2],\n",
              "       [3],\n",
              "       [4],\n",
              "       [5]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOKq0HfvuSXD",
        "outputId": "0029cf7d-1192-44f7-ca83-afc65a31a831"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 2],\n",
              "       [3, 4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "x = x.reshape((2, 3))\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.reshape((3,2))\n",
        "x"
      ],
      "metadata": {
        "id": "6V2W45u0ckG5",
        "outputId": "9cfcb12e-8c9f-48b4-8738-ec094655fc94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1],\n",
              "       [2, 3],\n",
              "       [4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29lDsGrruSXE"
      },
      "outputs": [],
      "source": [
        "x = np.zeros((300, 20))\n",
        "x = np.transpose(x)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((300, 20))\n",
        "x = np.transpose(x)\n",
        "x.shape\n",
        "x"
      ],
      "metadata": {
        "id": "3DRi3yWac0SY",
        "outputId": "790fe339-d560-49ca-d258-7dffb1c8489f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh6R6gLCuSXF"
      },
      "source": [
        "#### Geometric interpretation of tensor operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMDScZjcuSXF"
      },
      "source": [
        "#### A geometric interpretation of deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLz-Oiz-uSXF"
      },
      "source": [
        "### The engine of neural networks: Gradient-based optimization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#output = relu(matmul(input, W) +b)"
      ],
      "metadata": {
        "id": "_ndzIHfwgcJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#f(x + epsilon_x) = y + a * epsilon_x"
      ],
      "metadata": {
        "id": "DpAinlRKgk1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#I USE MY MODEL'S WEIGHTS W TO MAKE A PREDICTION FOR X\n",
        "y_pred = matmul(x, W)\n",
        "#We estimate how far off the prediction was\n",
        ";oss_value = loss(y_pred, y_true)"
      ],
      "metadata": {
        "id": "uarpF_8KhZ0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loss_value = f(W)"
      ],
      "metadata": {
        "id": "Zv9y_tBEkAG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2kRTKvjuSXG"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "#### What's a derivative?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN_qrsqluSXG"
      },
      "source": [
        "#### Derivative of a tensor operation: The gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKy3EcQluSXG"
      },
      "source": [
        "#### Stochastic gradient descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh850caQuSXG"
      },
      "source": [
        "#### Chaining derivatives: The Backpropagation algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kikyhSTXuSXH"
      },
      "source": [
        "##### The chain rule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0aH-WSyuSXH"
      },
      "source": [
        "##### Automatic differentiation with computation graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adzYCv4ruSXH"
      },
      "source": [
        "### Looking back at our first example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0qCJmVLuSXH"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n",
        "#train_images = train_images.reshape((60000, 28 * 28))\n",
        "#train_images = train_images.astype('float32') / 255\n",
        "#test_images = test_images.reshape((10000, 28 * 28))\n",
        "#test_images = test_images.astype('float32') / 255"
      ],
      "metadata": {
        "id": "E7ERwv1XtJ3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnT1givGuSXH"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model = keras.Sequentual(\n",
        "#    [\n",
        "#        layers.Dense(512, activation=\"relu\"),\n",
        "#        layers.Dense(10, activation=\"softmax\"),\n",
        "#    ]\n",
        "#)"
      ],
      "metadata": {
        "id": "PRuHuLuRuJPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VjJjgA8uSXI"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.compile(\n",
        "#    optimizer=\"adam\"\n",
        "#    loss= \"sparse_categorical_crossentropy\"\n",
        "#    metrics=[\"accuracy\"],\n",
        "#)"
      ],
      "metadata": {
        "id": "LkC3vfwsuiyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1MvCwWiuSXJ"
      },
      "outputs": [],
      "source": [
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=5,\n",
        "    batch_size=128,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.fit(\n",
        "#    train_images,\n",
        "#    train_labels,\n",
        "#    epochs=5\n",
        "#    batch_size=128,\n",
        "#`)"
      ],
      "metadata": {
        "id": "JgRT0747u2HO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wf3AznofuSXK"
      },
      "source": [
        "#### Reimplementing our first example from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VoDCb7puSXK"
      },
      "source": [
        "##### A simple Dense class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRQLpbGJuSXL"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import ops\n",
        "\n",
        "class NaiveDense:\n",
        "    def __init__(self, input_size, output_size, activation=None):\n",
        "        self.activation = activation\n",
        "        self.W = keras.Variable(\n",
        "            shape=(input_size, output_size), initializer=\"uniform\"\n",
        "        )\n",
        "        self.b = keras.Variable(shape=(output_size,), initializer=\"zeros\")\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        x = ops.matmul(inputs, self.W)\n",
        "        x = x + self.b\n",
        "        if self.activation is not None:\n",
        "            x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "        return [self.W, self.b]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import keras\n",
        "#from keras import ops\n",
        "\n",
        "#class NaiveDense:\n",
        "#  def __init__(self,input_size, output_size, activation=None):\n",
        "#    self.activation = activation\n",
        "#    self.W = keras.Variable(\n",
        "#        shape=(input_size, output_size), initializer=\"uniform\"\n",
        "#    )\n",
        "#    self.b = keras.Variable(shape=(output_size,), initializer=\"zeros\")\n",
        "\n",
        "#    def __call__(self, inputs):\n",
        "#      x = ops.matmul(inputs, self.W)\n",
        "#      x = x +self.b\n",
        "#      if self.activation is not None:\n",
        "#        x = self.activation(x)\n",
        "#      return x\n",
        "\n",
        "#    property\n",
        "#    def weights(self):\n",
        "#       return[self.W, self.b]\n",
        ""
      ],
      "metadata": {
        "id": "oWzPfWwfwBkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7zjxlJ2uSXL"
      },
      "source": [
        "##### A simple Sequential class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmSEks3euSXL"
      },
      "outputs": [],
      "source": [
        "class NaiveSequential:\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "        weights = []\n",
        "        for layer in self.layers:\n",
        "            weights += layer.weights\n",
        "        return weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#class NaiveSequential:\n",
        "#    def __init__(self, layers):\n",
        "#      self.layers = layers\n",
        "\n",
        "#    def _call__(self, inputs):\n",
        "#      x = inputs\n",
        "#      for layer in self.layers:\n",
        "#        x = layer(x)\n",
        "#        return x\n",
        "\n",
        "    @property\n",
        "#    def weights(self):\n",
        "#      weights = []\n",
        "#      for layer in self.layers:\n",
        "#        weights += layers.weights\n",
        "#        return weights"
      ],
      "metadata": {
        "id": "qFXbyKZoyOaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3K5yW-npuSXM"
      },
      "outputs": [],
      "source": [
        "model = NaiveSequential(\n",
        "    [\n",
        "        NaiveDense(input_size=28 * 28, output_size=512, activation=ops.relu),\n",
        "        NaiveDense(input_size=512, output_size=10, activation=ops.softmax),\n",
        "    ]\n",
        ")\n",
        "assert len(model.weights) == 4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model = NaiveSequential(\n",
        "#    [\n",
        "#        NaiveDense(input_size=28, output_size=512, activation=ops.relu),\n",
        "#        NaiveDense(inout_size=512, output_size=10, activation=ops.softmax),\n",
        "#    ]\n",
        "#)"
      ],
      "metadata": {
        "id": "-my9nPhmzcbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6co-jSsuSXN"
      },
      "source": [
        "##### A batch generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "om_aKX5ZuSXN"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class BatchGenerator:\n",
        "    def __init__(self, images, labels, batch_size=128):\n",
        "        assert len(images) == len(labels)\n",
        "        self.index = 0\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.num_batches = math.ceil(len(images) / batch_size)\n",
        "\n",
        "    def next(self):\n",
        "        images = self.images[self.index : self.index + self.batch_size]\n",
        "        labels = self.labels[self.index : self.index + self.batch_size]\n",
        "        self.index += self.batch_size\n",
        "        return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import math\n",
        "#class BatchGenerator:\n",
        "#  def __init__(self, images, labels, batch_size=128):\n",
        "#    assert len(images) == len(labels)\n",
        "#    self.index = 0\n",
        "#    self.images = images\n",
        "#    self.labels = labels\n",
        "#    self.batch_size = batch_size\n",
        "#    self.num_batches = math.ceil(len(images) / batch_size)\n",
        "\n",
        "#  def next(self):\n",
        "#    images = self.images[self.index : self.index + self.batch_size]\n",
        "#    labels = self.labels[self.index : self.index + self.batch_size]\n",
        "#    self.index += self.batch_size\n",
        "#    return images, labels\n"
      ],
      "metadata": {
        "id": "yD094ICS0QiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT77U1ZRuSXN"
      },
      "source": [
        "#### Running one training step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_Atjh8WuSXO"
      },
      "source": [
        "##### The weight update step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea8zQhsquSXO"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "    for g, w in zip(gradients, weights):\n",
        "        w.assign(w - g * learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#learning_rate = 1e-3\n",
        "\n",
        "#def update_weights(gradients, weights):\n",
        "#    for g, w in zip(gradients, weights):\n",
        "#      w.assign(w - g * learning_rate)"
      ],
      "metadata": {
        "id": "aRdPi6r42G3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7SafjI-uSXO"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "\n",
        "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "    optimizer.apply_gradients(zip(gradients, weights))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras import optimizers\n",
        "\n",
        "#optimizer = optimizers.SGD(learning_rate=1e-3)\n",
        "\n",
        "#def update_weights(gradients, weights):\n",
        "#  optimizers.apply_gradients(zip(gradients,weights))"
      ],
      "metadata": {
        "id": "06A5d3uo2lT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuzfowkKuSXO"
      },
      "source": [
        "##### Gradient computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oR8AimrsuSXP"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.zeros(shape=())\n",
        "with tf.GradientTape() as tape:\n",
        "    y = 2 * x + 3\n",
        "grad_of_y_wrt_x = tape.gradient(y, x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%backend tensorflow\n",
        "#import tensorflow as tf\n",
        "#x = tf.zeros(shape=())\n",
        "#with tf.GradientTape() as tape:\n",
        "#  y = 2 * x + 3\n",
        "#grad_of_y_wrt_x = tape.gradient(y, x)"
      ],
      "metadata": {
        "id": "uwBPYVUI3Odb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XxUEh2zuSXP"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "def one_training_step(model, images_batch, labels_batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images_batch)\n",
        "        loss = ops.sparse_categorical_crossentropy(labels_batch, predictions)\n",
        "        average_loss = ops.mean(loss)\n",
        "    gradients = tape.gradient(average_loss, model.weights)\n",
        "    update_weights(gradients, model.weights)\n",
        "    return average_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%backend tensorflow\n",
        "#def one_training_step(model, images_batch, labels_batch):\n",
        "#  with tf.GradientTape() as tape:\n",
        "#    predictions = model(images_batch)\n",
        "#    loss = ops.sparse_categorical_crossentropy(labels_batch, predictions)\n",
        "#    average_loss = ops.mean(loss)\n",
        "#  gradients = tape.gradient(average_loss, model.weights)\n",
        "#  update_weights(gradients, model.weights)\n",
        "#  return average_loss"
      ],
      "metadata": {
        "id": "P6I7ugDu38S3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm3tUVlFuSXP"
      },
      "source": [
        "#### The full training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sN0vzcGUuSXQ"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "def fit(model, images, labels, epochs, batch_size=128):\n",
        "    for epoch_counter in range(epochs):\n",
        "        print(f\"Epoch {epoch_counter}\")\n",
        "        batch_generator = BatchGenerator(images, labels)\n",
        "        for batch_counter in range(batch_generator.num_batches):\n",
        "            images_batch, labels_batch = batch_generator.next()\n",
        "            loss = one_training_step(model, images_batch, labels_batch)\n",
        "            if batch_counter % 100 == 0:\n",
        "                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%backend tensorflow\n",
        "#def fit(model, images, labels, epochs, batch_size=128):\n",
        "#  for epoch_counter in range(epochs):\n",
        "#    print(f\"Epoch {epoch_counter}\")\n",
        "#    batch_generator = BatchGenerator(images, labels)\n",
        "#    for batch_counter in range(batch_generator.num_batches):\n",
        "#      images_batch, labels_batch = batch_generator.next()\n",
        "#      loss = one_training_step(model, images_batch, labels_batch)\n",
        "#      of batch_counter % 100 == 0:\n",
        "#      print(f\"loss at batch {batch_counter}: {loss: .2f}\")"
      ],
      "metadata": {
        "id": "rQeYQq5n49dZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6gFHh2ruSXQ"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255\n",
        "\n",
        "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%backend tensorflow\n",
        "#from keras.datasets import mnist\n",
        "\n",
        "#(train_images, train_labels), (test_images. test_images) = mnist.load_data()\n",
        "#train_images = train_images.reshape((60000, 28 * 28))\n",
        "#train_images = train_images.astype(\"float32\") / 255\n",
        "#test_images = test_images.reshape((10000, 28 * 28))\n",
        "#test_images = test_images.astype('float32') / 255\n",
        "\n",
        "#fit(model, train_images, train_labels, epochs=10, batch_size=128)"
      ],
      "metadata": {
        "id": "8pyoGzFY8tWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0pOBj6duSXQ"
      },
      "source": [
        "#### Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smza2Ac7uSXQ"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "predictions = model(test_images)\n",
        "predicted_labels = ops.argmax(predictions, axis=1)\n",
        "matches = predicted_labels == test_labels\n",
        "f\"accuracy: {ops.mean(matches):.2f}\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%backend tensorflow\n",
        "#predictions = model(test_images)\n",
        "#predicted_labels = ops.argmax(predictions, axis=1)\n",
        "#matches = predicted_labels == test_labels\n",
        "#f\"accuracy: {ops.mean(matchs):.2f}\""
      ],
      "metadata": {
        "id": "NfI-z5VU95yJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "chapter02_mathematical-building-blocks",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}